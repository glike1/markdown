美国纽约、波特兰和西雅图三大城市正式被列为无政府主义地区。
这意味着美国政府对这三个城市将：
**允许暴力和财产破坏持续存在;**
**拒绝采取合理措施打击犯罪活动.**
![](2020-10-03-21-11-55.png)
早在9月2日，特朗普就发布备忘录呼吁对“黑人的命也是命（BLM）”游行及后续引发的“暴行”进行抗议，并点名纽约市、波特兰市和西雅图市，将动乱归咎于这三个城市的地方官员。他威胁到，如果不采取行动就要扣留联邦资金。
随后，美国司法部很快作出回应，将这件事落实了。总检察长威廉·巴尔说： “当公民的安全还没得到解决时，我们不能允许浪费联邦税收。我希望，司法部今天确定的城市将扭转局面，认真履行政府的基本职能，并开始保护自己的公民。”
那么，纽约、波特兰、西雅图这三个城市到底做了什么？怎么就变成“无政府主义管辖区”了？

在今年5月，黑人男子弗洛伊德被警察无辜跪杀后，美国多地爆发了大规模针对警察暴行和种族主义的抗议活动。

也就是在这个时候，美国，失控了。
暴动、骚乱、示威，除了混乱还是混乱。

据官方环球时报报道，如今美国司法部则是落实了特朗普在这份备忘录中提出的内容，正式确认纽约、波特兰和西雅图属于“无政府主义辖区”。美国白宫管理和预算办公室也将在两周内就砍掉三地哪些联邦拨款给出细则。
![](2020-10-03-21-16-18.png)
但是由于民主党今年总统大选的竞选策略，是通过支持这些反种族主义抗议者来打击特朗普在种族问题上的形象和支持率，所以在纽约、波特兰和西雅图这三座由民主党控制的城市里，当地官员和执法部门并没有对抗议者中出现的暴乱行为采取打击措施。但这种应对策略却导致三座城市的犯罪率都出现了增加。
![](2020-10-03-21-16-44.png)
自暴乱发生以来，三座城市的犯罪率可以说是节节上升，就拿纽约来说，7月枪击事件发生的概率就猛增到177%，8月记录在案的枪击案就多达242起，比去年多了91起。
与此同时，特朗普仍然在进行着他的“推特治国”。
![](2020-10-03-21-27-10.png)
在过去几个月里，特朗普曾数次在他的社交帐号发布这种要求“法律与秩序”的条文。
据独立日报7月2日报道，纽约市长比尔·白思豪(Bill de Blasio)在纽约第五大道的一幅名为“黑人的生命也是命”(Black Lives Matter)的壁画上作画，特朗普对此表示不满，他在推特上表示，这种艺术会“激怒”执法部门；
据环球时报报道，8月30日早上，不到6时特朗普就开始上推特发言，当天他发布和转发的推文多达近90条。其中多条推文都是在攻击波特兰市市长。
![](2020-10-03-21-39-39.png)
“推特治国”成效如何？
![](2020-10-03-21-44-35.png)
<center>词云图中文版,摘自Python知识圈公众号</center>

![](2020-10-03-21-53-19.png)
<center>词云图英文版</center>
在基于python的词云分析中，提及最多的(除了特朗普，他的本名外)为让美国再次伟大(make American first)、假新闻(fake news)、各个知名媒体(fox、nbc、cnn),以及前任总统奥巴马和中国(CHINA!)。

除了众所周知的甩锅奥巴马和中国，我们还知道特朗普跟主流媒体并不十分合得来。
![](2020-10-03-21-57-08.png)
![](2020-10-03-22-10-15.png)
**<center>使用python自然语言处理(NLP)之后得到的情绪分析，其中y轴表示积极的情绪，x轴表示中性情绪，z轴表示消极的情绪（或愤慨)</center>**
媒体舆论
右派媒体
福克斯新闻：美国司法部响应特朗普的要求，重新审核针对纽约、波特兰和西雅图三个城市的联邦拨款，将其认定为允许“无政府、暴力和破坏”的管辖区。
the blaze：美国司法部将纽约、波特兰和西雅图列为“无政府主义管辖区”，将寻求方法撤销他们的联邦基金，“我们绝不允许联邦资金被浪费”。
左派媒体
微软全国广播公司节目：特朗普苟合司法部将纽约市指定为“无政府主义辖区“，这是一种消除异见的厚颜无耻的策略。为了抗击新冠疫情，纽约市艰难地应对预算短缺问题，却有可能被剥夺其联邦拨款。
纽约时报：特朗普利用美国国家环境保护局扩大与纽约的“无政府主义”战争。特朗普政府威胁取消纽约市的联邦拨款被鄙视，被认为是政治化的选举策略。
国际媒体
BBC：特朗普政府将三个城市界定为“无政府主义辖区”，认为他们容忍犯罪，这一举措将使这些城市失去联邦基金。总检察长William Barr呼吁三个城市的政府“迷途知返，认真履行政府职责，保护他们的公民”。
从中可以看出，有一部分媒体认为这是特朗普的竞选策略，因为这三个地区基本也都是特朗普支持率最低的地区。
![](2020-10-03-22-04-33.png)
主流媒体这样的考虑不无道理。“按照传统”，美国大选总是会有此类操作。“十月惊奇”这一政治术语由美国前总统尼克松的助手威廉·凯西1980年首次提出，那时凯西担任里根竞选团队的经理。顾名思义，“十月惊奇”是指在美国大选前最后一刻出现的一些影响双方选情的突发事件，如2016年美国联邦调查局重启对希拉里“邮件门”的调查。在研究美国选举政治的中外学者看来，“十月惊奇”可能会彻底改变整个选举进程，也可能会强化不可避免的选举结果。

附录代码

    
    import os
    import nltk
    import pandas as pd
    from wordcloud import WordCloud
    from cutecharts.charts import Pie
    from cutecharts.charts import Bar
    from cutecharts.charts import Line
    from cutecharts.charts import Radar
    from nltk.sentiment.vader import SentimentIntensityAnalyzer


    def checkDir(dirpath):
        if not os.path.exists(dirpath):
            os.mkdir(dirpath)
            return False
        return True


    def readCSV(filepath='twitters.csv'):
        data = pd.read_csv(filepath, lineterminator='\n')
        data['time'] = pd.to_datetime(data['created_at']).dt.tz_convert(
            'US/Eastern').dt.strftime('%Y/%m/%d %H:%M:%S')
        data['time'] = pd.to_datetime(data['time'])
        return data


    def drawLine(title, data, series_name, x_label, y_label, savedir='results'):
        checkDir(savedir)
        chart = Line(title)
        chart.set_options(
            labels=list(data.keys()),
            x_label=x_label,
            y_label=y_label
        )
        chart.add_series(series_name, list(data.values()))
        chart.render(os.path.join(savedir, title+'.html'))


    def drawBar(title, data, series_name, x_label, y_label, savedir='results'):
        checkDir(savedir)
        chart = Bar(title)
        chart.set_options(
            labels=list(data.keys()),
            x_label=x_label,
            y_label=y_label
        )
        chart.add_series(series_name, list(data.values()))
        chart.render(os.path.join(savedir, title+'.html'))


    def drawPie(title, data, savedir='results'):
        checkDir(savedir)
        chart = Pie(title)
        chart.set_options(labels=list(data.keys()))
        chart.add_series(list(data.values()))
        chart.render(os.path.join(savedir, title+'.html'))


    def drawRadar(title, datas, series_names, savedir='results'):
        checkDir(savedir)
        chart = Radar(title)
        chart.set_options(labels=list(datas[0].keys()))
        for data, series_name in zip(datas, series_names):
            chart.add_series(series_name, list(data.values()))
        chart.render(os.path.join(savedir, title+'.html'))


    def statisticsWF(texts, stopwords):
        words_dict = {}
        for text in texts:
            words = text.split(' ')
            for word in words:
                word = word.lower().replace('[', '').replace(
                    ']', '').replace('.', '').replace(',', '')
                if word in stopwords:
                    continue
                if word in words_dict.keys():
                    words_dict[word] += 1
                else:
                    words_dict[word] = 1
        return words_dict


    def drawWordCloud(words, title, savedir='results'):
        checkDir(savedir)
        wc = WordCloud(font_path='font.TTF', background_color='white',
                    max_words=2000, width=1920, height=1080, margin=5)
        wc.generate_from_frequencies(words)
        wc.to_file(os.path.join(savedir, title+'.png'))


    if __name__ == '__main__':
        twitters = readCSV('twitters.csv')
        num_twitters_per_year = {}
        for item in twitters['time']:
            if item.year in num_twitters_per_year:
                num_twitters_per_year[item.year] += 1
            else:
                num_twitters_per_year[item.year] = 1
        num_twitters_per_year = dict(
            sorted(num_twitters_per_year.items(), key=lambda item: item[0]))
        print(num_twitters_per_year)
        drawLine('特朗普每年发的推特数量', num_twitters_per_year,
                '推特数量', x_label='年份', y_label='数量')
        num_twitters_per_device = {}
        for item in twitters['source']:
            item = item.replace('Twitter for ', '').replace(
                'Twitter ', '').replace('Twitter Mirror for ', '')
            if item in num_twitters_per_device:
                num_twitters_per_device[item] += 1
            else:
                num_twitters_per_device[item] = 1
        num_twitters_per_device = dict(
            sorted(num_twitters_per_device.items(), key=lambda item: item[1])[-5:])
        drawBar('特朗普都用哪些设备发推特', num_twitters_per_device,
                '设备类型', x_label='设备类型', y_label='数量')
        num_twitters_per_period = {}
        for item in twitters['time']:
            if item.hour in num_twitters_per_period:
                num_twitters_per_period[item.hour] += 1
            else:
                num_twitters_per_period[item.hour] = 1
        num_twitters_per_period = dict(
            sorted(num_twitters_per_period.items(), key=lambda item: item[0]))
        drawLine('特朗普发推特的时间统计', num_twitters_per_period,
                '推特数量', x_label='时间', y_label='数量')
        num_obama_per_year = {}
        for item in zip(twitters['time'], twitters['text']):
            if item[0].year in num_obama_per_year:
                num_obama_per_year[item[0].year] += int('obama' in item[1].lower())
            else:
                num_obama_per_year[item[0].year] = int('obama' in item[1].lower())
        num_obama_per_year = dict(
            sorted(num_obama_per_year.items(), key=lambda item: item[0])[-3:])
        drawPie('特朗普上任后每年提到奥巴马的次数', num_obama_per_year)
        nltk.download('vader_lexicon')
        sid = SentimentIntensityAnalyzer()
        neg_or_pos_for_obama = {'pos': 0, 'neg': 0, 'neu': 0}
        for item in twitters['text']:
            if 'obama' in item.lower():
                score = sid.polarity_scores(item)
                score.update({'compound': -1e5})
                neg_or_pos_for_obama[max(score, key=score.get)] += 1
        drawPie('特朗普奥巴马相关的推特情绪分析', neg_or_pos_for_obama)
        num_twitters_per_media = {}
        medias = ['fortune magazine', 'national review', 'politico', 'los angeles times', 'guardian', 'usa today',
                'new hampshire union leader', 'esquire magazine', 'cnet', 'gq magazine', 'weekly standard', 'hbo',
                'tmz', 'npr', 'los angeles daily', 'bloomberg', 'the view', 'univision', 'newsweek', 'wall street journal',
                'techmeme', 'huffington post', 'meet the press', 'cnn', 'fox', 'national journal', 'msnbc', 'bbc', 'buzzfeed',
                'cnbc', 'des moines register ', 'time magazine', 'vanity fair', 'ny mag', 'cbs', 'ny post', 'ny daily', "o'reilly factor",
                'espn', 'charlie hebdo', 'associated press', 'morning joe', 'deadspin', 'time magazine ', 'washington post', 'palm beach post',
                'rolling stone', 'nbc', 'new york times', 'abc', 'huffpost']
        for media in medias:
            num_twitters_per_media[media] = 0
        for item in twitters['text']:
            for media in medias:
                if media in item.lower():
                    num_twitters_per_media[media] += 1
        num_twitters_per_media = dict(
            sorted(num_twitters_per_media.items(), key=lambda item: item[1])[-6:])
        drawBar('特朗普提到最多的六大美国媒体', num_twitters_per_media,
                '媒体', x_label='媒体', y_label='数量')
        sid = SentimentIntensityAnalyzer()
        neg_or_pos_for_fox = {'pos': 0, 'neg': 0, 'neu': 0}
        neg_or_pos_for_nbc = {'pos': 0, 'neg': 0, 'neu': 0}
        neg_or_pos_for_cnn = {'pos': 0, 'neg': 0, 'neu': 0}
        for item in twitters['text']:
            if 'fox' in item.lower():
                score = sid.polarity_scores(item)
                flag = True
                if score['neg'] > 0.1:
                    neg_or_pos_for_fox['neg'] += 1
                    flag = False
                if score['pos'] > 0.2:
                    neg_or_pos_for_fox['pos'] += 1
                    flag = False
                if flag:
                    score.update({'compound': -1e5})
                    neg_or_pos_for_fox[max(score, key=score.get)] += 1
            if 'nbc' in item.lower():
                score = sid.polarity_scores(item)
                flag = True
                if score['neg'] > 0.1:
                    neg_or_pos_for_nbc['neg'] += 1
                    flag = False
                if score['pos'] > 0.2:
                    neg_or_pos_for_nbc['pos'] += 1
                    flag = False
                if flag:
                    score.update({'compound': -1e5})
                    neg_or_pos_for_nbc[max(score, key=score.get)] += 1
            if 'cnn' in item.lower():
                score = sid.polarity_scores(item)
                flag = True
                if score['neg'] > 0.1:
                    neg_or_pos_for_cnn['neg'] += 1
                    flag = False
                if score['pos'] > 0.2:
                    neg_or_pos_for_cnn['pos'] += 1
                    flag = False
                if flag:
                    score.update({'compound': -1e5})
                    neg_or_pos_for_cnn[max(score, key=score.get)] += 1
        drawRadar('特朗普FOX_NBC_CNN相关的推特情绪分析', [
                neg_or_pos_for_fox, neg_or_pos_for_nbc, neg_or_pos_for_cnn], ['fox', 'nbc', 'cnn'])
        stopwords = open('enstopwords.data', 'r',
                        encoding='utf-8').read().split('\n')
        texts = [item for item in twitters['text']]
        words_dict = statisticsWF(texts, stopwords)
        drawWordCloud(words_dict, '特朗普推特词云')
